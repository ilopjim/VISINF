{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Comment this if the data visualisations doesn't work on your side\n",
    "%matplotlib inline\n",
    "\n",
    "#plt.style.use('bmh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V203</th>\n",
       "      <th>V191</th>\n",
       "      <th>V212</th>\n",
       "      <th>V202</th>\n",
       "      <th>V187</th>\n",
       "      <th>V185</th>\n",
       "      <th>V186</th>\n",
       "      <th>V180</th>\n",
       "      <th>V242</th>\n",
       "      <th>V167</th>\n",
       "      <th>...</th>\n",
       "      <th>V149</th>\n",
       "      <th>V238</th>\n",
       "      <th>V154</th>\n",
       "      <th>V161</th>\n",
       "      <th>V234</th>\n",
       "      <th>V194</th>\n",
       "      <th>V207</th>\n",
       "      <th>V173</th>\n",
       "      <th>V174</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ref</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201390679</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201390959</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>688.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201397626</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201397742</th>\n",
       "      <td>99.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>872.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201401345</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1143.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           V203  V191    V212  V202    V187   V185    V186    V180  V242  \\\n",
       "ref                                                                        \n",
       "201390679   0.0   7.0   199.0  27.0  9999.0  113.0  9999.0  9999.0  15.0   \n",
       "201390959   0.0   4.0   688.0  47.0  9999.0    1.0  9999.0  9999.0  32.0   \n",
       "201397626   0.0  11.0  1140.0  36.0  9999.0  130.0  9999.0  9999.0  32.0   \n",
       "201397742  99.0   8.0   872.0  25.0  9999.0   69.0  9999.0  9999.0  28.0   \n",
       "201401345   0.0   8.0  1143.0  33.0    28.0  181.0   110.0    19.0  18.0   \n",
       "\n",
       "           V167 ...  V149  V238  V154  V161  V234  V194  V207  V173  V174  y  \n",
       "ref             ...                                                           \n",
       "201390679   7.0 ...     0     1     1     0     0     4     6     0     0  0  \n",
       "201390959   7.0 ...     0     0     0     0     0     0     0     0     0  0  \n",
       "201397626   7.0 ...     0     0     0     0     1     5     0     0     0  0  \n",
       "201397742   3.0 ...     0     0     0     0     0     0     1     0     0  0  \n",
       "201401345   8.0 ...     0     0     0     0     0    10     9     0     0  0  \n",
       "\n",
       "[5 rows x 118 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data_exploration_2.csv', low_memory=False, index_col = 'ref')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanceo de la variable respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    102703\n",
       "1      1211\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['y'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separar la clase mayoritaria y minoritaria de la variable respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# UpSampling\n",
    "df_majority = df[df.y==0]\n",
    "df_minority = df[df.y==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upsample clase minoritaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # muestra con reemplazamiento\n",
    "                                 n_samples=102703,    # hasta la clase mayoritaria\n",
    "                                 random_state=123) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combinar la clase mayoritaria con la muestra de la clase minoritaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    102703\n",
       "0    102703\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "df_upsampled.y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El nuevo Dataframe tiene más observaciones que el original, y el ratio de las dos clases de la variable respuesta es ahora 1:1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Down-Sample clase mayoritaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,    # muestra sin reemplazamiento\n",
    "                                 n_samples=1211,     # hasta la clase minoritaria\n",
    "                                 random_state=123) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combinar la clase minoritaria con la muestra de la clase mayoritaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1211\n",
       "0    1211\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine minority class with downsampled majority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    " \n",
    "# Display new class counts\n",
    "df_downsampled.y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Importancia de las variables y selección"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_up = df_upsampled[df_upsampled.columns[:-1]]\n",
    "y_up = df_upsampled['y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 62 (0.102744)\n",
      "2. feature 18 (0.063529)\n",
      "3. feature 46 (0.059097)\n",
      "4. feature 64 (0.055788)\n",
      "5. feature 45 (0.055639)\n",
      "6. feature 14 (0.045793)\n",
      "7. feature 76 (0.044943)\n",
      "8. feature 2 (0.043734)\n",
      "9. feature 71 (0.043185)\n",
      "10. feature 90 (0.036315)\n",
      "11. feature 114 (0.035213)\n",
      "12. feature 72 (0.032754)\n",
      "13. feature 19 (0.020904)\n",
      "14. feature 40 (0.020836)\n",
      "15. feature 15 (0.020691)\n",
      "16. feature 113 (0.017814)\n",
      "17. feature 6 (0.016237)\n",
      "18. feature 9 (0.015551)\n",
      "19. feature 0 (0.013624)\n",
      "20. feature 12 (0.012660)\n",
      "21. feature 10 (0.012636)\n",
      "22. feature 70 (0.012046)\n",
      "23. feature 69 (0.011691)\n",
      "24. feature 7 (0.011338)\n",
      "25. feature 39 (0.008011)\n",
      "26. feature 1 (0.007689)\n",
      "27. feature 86 (0.007366)\n",
      "28. feature 20 (0.007269)\n",
      "29. feature 77 (0.006566)\n",
      "30. feature 27 (0.005938)\n",
      "31. feature 16 (0.005930)\n",
      "32. feature 65 (0.005581)\n",
      "33. feature 34 (0.005551)\n",
      "34. feature 91 (0.005548)\n",
      "35. feature 26 (0.005401)\n",
      "36. feature 38 (0.004668)\n",
      "37. feature 81 (0.004662)\n",
      "38. feature 8 (0.004636)\n",
      "39. feature 11 (0.004450)\n",
      "40. feature 47 (0.004393)\n",
      "41. feature 89 (0.004331)\n",
      "42. feature 110 (0.004200)\n",
      "43. feature 24 (0.003628)\n",
      "44. feature 17 (0.003383)\n",
      "45. feature 41 (0.003372)\n",
      "46. feature 43 (0.003353)\n",
      "47. feature 21 (0.002781)\n",
      "48. feature 42 (0.002673)\n",
      "49. feature 73 (0.002656)\n",
      "50. feature 80 (0.002549)\n",
      "51. feature 75 (0.002279)\n",
      "52. feature 58 (0.002221)\n",
      "53. feature 79 (0.002200)\n",
      "54. feature 48 (0.002183)\n",
      "55. feature 5 (0.002180)\n",
      "56. feature 74 (0.002129)\n",
      "57. feature 4 (0.002084)\n",
      "58. feature 63 (0.002042)\n",
      "59. feature 59 (0.002003)\n",
      "60. feature 44 (0.001990)\n",
      "61. feature 23 (0.001859)\n",
      "62. feature 87 (0.001847)\n",
      "63. feature 85 (0.001843)\n",
      "64. feature 33 (0.001811)\n",
      "65. feature 36 (0.001794)\n",
      "66. feature 31 (0.001763)\n",
      "67. feature 13 (0.001710)\n",
      "68. feature 68 (0.001639)\n",
      "69. feature 78 (0.001592)\n",
      "70. feature 55 (0.001455)\n",
      "71. feature 88 (0.001427)\n",
      "72. feature 37 (0.001419)\n",
      "73. feature 30 (0.001416)\n",
      "74. feature 32 (0.001351)\n",
      "75. feature 22 (0.001296)\n",
      "76. feature 111 (0.001271)\n",
      "77. feature 3 (0.001194)\n",
      "78. feature 83 (0.001179)\n",
      "79. feature 29 (0.001163)\n",
      "80. feature 112 (0.001151)\n",
      "81. feature 115 (0.001143)\n",
      "82. feature 105 (0.001058)\n",
      "83. feature 107 (0.001039)\n",
      "84. feature 54 (0.001018)\n",
      "85. feature 56 (0.001011)\n",
      "86. feature 52 (0.000957)\n",
      "87. feature 28 (0.000910)\n",
      "88. feature 53 (0.000894)\n",
      "89. feature 25 (0.000892)\n",
      "90. feature 57 (0.000845)\n",
      "91. feature 35 (0.000807)\n",
      "92. feature 67 (0.000718)\n",
      "93. feature 84 (0.000603)\n",
      "94. feature 109 (0.000536)\n",
      "95. feature 82 (0.000524)\n",
      "96. feature 51 (0.000503)\n",
      "97. feature 98 (0.000482)\n",
      "98. feature 49 (0.000378)\n",
      "99. feature 102 (0.000362)\n",
      "100. feature 50 (0.000360)\n",
      "101. feature 108 (0.000354)\n",
      "102. feature 96 (0.000288)\n",
      "103. feature 116 (0.000204)\n",
      "104. feature 106 (0.000178)\n",
      "105. feature 100 (0.000151)\n",
      "106. feature 103 (0.000135)\n",
      "107. feature 97 (0.000132)\n",
      "108. feature 92 (0.000124)\n",
      "109. feature 66 (0.000100)\n",
      "110. feature 60 (0.000098)\n",
      "111. feature 99 (0.000090)\n",
      "112. feature 95 (0.000084)\n",
      "113. feature 104 (0.000064)\n",
      "114. feature 93 (0.000057)\n",
      "115. feature 101 (0.000050)\n",
      "116. feature 94 (0.000017)\n",
      "117. feature 61 (0.000000)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEICAYAAABbOlNNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlJihJtIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xdf61230>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature Importance\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# fit an Extra Trees model to the data\n",
    "model = ExtraTreesClassifier(random_state = seed)\n",
    "model.fit(X_up, y_up)\n",
    "importances = model.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in model.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "#df_ETC =pd.DataFrame()\n",
    "for f in range(X_up.shape[1]):\n",
    "#    df_ETC = pd.concat(X[X.columns[:f]], axis = 1)\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]] ))\n",
    "    \n",
    "    \n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_up.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X_up.shape[1]), indices)\n",
    "plt.xlim([-1, X_up.shape[1]])\n",
    "plt.show()\n",
    "# display the relative importance of each attribute\n",
    "#print(model.feature_importances_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_dwn = df_downsampled[df_downsampled.columns[:-1]]\n",
    "y_dwn = df_downsampled['y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 62 (0.140149)\n",
      "2. feature 46 (0.066204)\n",
      "3. feature 18 (0.057097)\n",
      "4. feature 90 (0.049185)\n",
      "5. feature 14 (0.048999)\n",
      "6. feature 113 (0.038934)\n",
      "7. feature 45 (0.038692)\n",
      "8. feature 64 (0.037074)\n",
      "9. feature 10 (0.036739)\n",
      "10. feature 71 (0.036051)\n",
      "11. feature 76 (0.035676)\n",
      "12. feature 2 (0.033316)\n",
      "13. feature 19 (0.033019)\n",
      "14. feature 114 (0.024171)\n",
      "15. feature 72 (0.020953)\n",
      "16. feature 20 (0.014381)\n",
      "17. feature 39 (0.011894)\n",
      "18. feature 7 (0.011615)\n",
      "19. feature 8 (0.010651)\n",
      "20. feature 16 (0.009970)\n",
      "21. feature 110 (0.009453)\n",
      "22. feature 86 (0.008803)\n",
      "23. feature 112 (0.008669)\n",
      "24. feature 11 (0.008630)\n",
      "25. feature 12 (0.007819)\n",
      "26. feature 9 (0.007475)\n",
      "27. feature 43 (0.007186)\n",
      "28. feature 27 (0.006960)\n",
      "29. feature 89 (0.006721)\n",
      "30. feature 33 (0.006571)\n",
      "31. feature 41 (0.006160)\n",
      "32. feature 34 (0.006089)\n",
      "33. feature 6 (0.005725)\n",
      "34. feature 0 (0.005636)\n",
      "35. feature 65 (0.005600)\n",
      "36. feature 40 (0.005582)\n",
      "37. feature 1 (0.005527)\n",
      "38. feature 68 (0.005013)\n",
      "39. feature 69 (0.004530)\n",
      "40. feature 24 (0.004496)\n",
      "41. feature 15 (0.004349)\n",
      "42. feature 70 (0.004328)\n",
      "43. feature 13 (0.004036)\n",
      "44. feature 91 (0.004025)\n",
      "45. feature 77 (0.004019)\n",
      "46. feature 42 (0.003621)\n",
      "47. feature 17 (0.003514)\n",
      "48. feature 80 (0.003501)\n",
      "49. feature 47 (0.003491)\n",
      "50. feature 81 (0.003058)\n",
      "51. feature 5 (0.002895)\n",
      "52. feature 73 (0.002756)\n",
      "53. feature 21 (0.002571)\n",
      "54. feature 111 (0.002485)\n",
      "55. feature 67 (0.002455)\n",
      "56. feature 26 (0.002384)\n",
      "57. feature 31 (0.002158)\n",
      "58. feature 63 (0.002122)\n",
      "59. feature 74 (0.002107)\n",
      "60. feature 32 (0.002068)\n",
      "61. feature 23 (0.002041)\n",
      "62. feature 87 (0.001993)\n",
      "63. feature 25 (0.001884)\n",
      "64. feature 75 (0.001742)\n",
      "65. feature 85 (0.001709)\n",
      "66. feature 22 (0.001699)\n",
      "67. feature 36 (0.001570)\n",
      "68. feature 29 (0.001542)\n",
      "69. feature 44 (0.001517)\n",
      "70. feature 88 (0.001497)\n",
      "71. feature 79 (0.001487)\n",
      "72. feature 109 (0.001487)\n",
      "73. feature 54 (0.001462)\n",
      "74. feature 104 (0.001382)\n",
      "75. feature 37 (0.001348)\n",
      "76. feature 116 (0.001329)\n",
      "77. feature 35 (0.001281)\n",
      "78. feature 52 (0.001259)\n",
      "79. feature 28 (0.001231)\n",
      "80. feature 78 (0.001167)\n",
      "81. feature 83 (0.001141)\n",
      "82. feature 3 (0.001102)\n",
      "83. feature 38 (0.000983)\n",
      "84. feature 56 (0.000939)\n",
      "85. feature 58 (0.000911)\n",
      "86. feature 57 (0.000899)\n",
      "87. feature 103 (0.000895)\n",
      "88. feature 48 (0.000869)\n",
      "89. feature 95 (0.000863)\n",
      "90. feature 30 (0.000807)\n",
      "91. feature 50 (0.000799)\n",
      "92. feature 53 (0.000752)\n",
      "93. feature 55 (0.000685)\n",
      "94. feature 101 (0.000667)\n",
      "95. feature 96 (0.000611)\n",
      "96. feature 102 (0.000586)\n",
      "97. feature 82 (0.000546)\n",
      "98. feature 4 (0.000541)\n",
      "99. feature 51 (0.000521)\n",
      "100. feature 59 (0.000461)\n",
      "101. feature 94 (0.000435)\n",
      "102. feature 115 (0.000417)\n",
      "103. feature 98 (0.000410)\n",
      "104. feature 84 (0.000377)\n",
      "105. feature 105 (0.000322)\n",
      "106. feature 106 (0.000319)\n",
      "107. feature 100 (0.000311)\n",
      "108. feature 97 (0.000306)\n",
      "109. feature 107 (0.000289)\n",
      "110. feature 99 (0.000286)\n",
      "111. feature 66 (0.000277)\n",
      "112. feature 108 (0.000275)\n",
      "113. feature 49 (0.000156)\n",
      "114. feature 92 (0.000137)\n",
      "115. feature 60 (0.000123)\n",
      "116. feature 93 (0.000000)\n",
      "117. feature 61 (0.000000)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEICAYAAABbOlNNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUGAQEZGK/wXZNVpj2l7n9QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xf5c0a70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.fit(X_dwn, y_dwn)\n",
    "importances2 = model.feature_importances_\n",
    "std2 = np.std([tree.feature_importances_ for tree in model.estimators_],\n",
    "             axis=0)\n",
    "indices2 = np.argsort(importances2)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "#df_ETC =pd.DataFrame()\n",
    "for f in range(X_dwn.shape[1]):\n",
    "#    df_ETC = pd.concat(X[X.columns[:f]], axis = 1)\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices2[f], importances2[indices2[f]] ))\n",
    "    \n",
    "    \n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_dwn.shape[1]), importances2[indices2],\n",
    "       color=\"r\", yerr=std2[indices2], align=\"center\")\n",
    "plt.xticks(range(X_dwn.shape[1]), indices2)\n",
    "plt.xlim([-1, X_dwn.shape[1]])\n",
    "plt.show()\n",
    "# display the relative importance of each attribute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, False, False, False,  True,  True, False,\n",
       "        True,  True, False,  True, False,  True,  True, False, False,\n",
       "        True,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "        True,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False,  True, False, False, False, False,  True,  True,  True,\n",
       "        True, False, False, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True,  True, False, False], dtype=bool)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances > 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_X = X_up.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables cuya importancia sea  > 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_FI_up = []\n",
    "count = 0\n",
    "for i in indices:\n",
    "    if importances[indices[i]] > 0.01:\n",
    "        col_FI_up.append(col_X[i])\n",
    "        count += importances[indices[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8047624378455176"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['V240',\n",
       " 'V182',\n",
       " 'V212',\n",
       " 'V241',\n",
       " 'V245',\n",
       " 'V186',\n",
       " 'V167',\n",
       " 'V203',\n",
       " 'V243',\n",
       " 'V189',\n",
       " 'V180',\n",
       " 'V191',\n",
       " 'V169',\n",
       " 'V244',\n",
       " 'V242',\n",
       " 'V188',\n",
       " 'V239',\n",
       " 'V226',\n",
       " 'V185',\n",
       " 'V187',\n",
       " 'V231',\n",
       " 'V196',\n",
       " 'V220',\n",
       " 'V202']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_FI_up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe - Feature importances - Upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V240</th>\n",
       "      <th>V182</th>\n",
       "      <th>V212</th>\n",
       "      <th>V241</th>\n",
       "      <th>V245</th>\n",
       "      <th>V186</th>\n",
       "      <th>V167</th>\n",
       "      <th>V203</th>\n",
       "      <th>V243</th>\n",
       "      <th>V189</th>\n",
       "      <th>...</th>\n",
       "      <th>V242</th>\n",
       "      <th>V188</th>\n",
       "      <th>V239</th>\n",
       "      <th>V226</th>\n",
       "      <th>V185</th>\n",
       "      <th>V187</th>\n",
       "      <th>V231</th>\n",
       "      <th>V196</th>\n",
       "      <th>V220</th>\n",
       "      <th>V202</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ref</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201390679</th>\n",
       "      <td>9999.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>945.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>102003.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201390959</th>\n",
       "      <td>9999.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>688.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>1530.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32005.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201397626</th>\n",
       "      <td>9999.0</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>1202.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>92002.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201397742</th>\n",
       "      <td>9999.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>872.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>1324.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42002.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201401345</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>1143.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112004.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             V240     V182    V212    V241  V245    V186  V167  V203  V243  \\\n",
       "ref                                                                          \n",
       "201390679  9999.0   3000.0   199.0  9999.0  13.0  9999.0   7.0   0.0  10.0   \n",
       "201390959  9999.0   1000.0   688.0  9999.0   0.0  9999.0   7.0   0.0   2.0   \n",
       "201397626  9999.0  19000.0  1140.0  9999.0   0.0  9999.0   7.0   0.0   2.0   \n",
       "201397742  9999.0   3000.0   872.0  9999.0   0.0  9999.0   3.0  99.0   3.0   \n",
       "201401345     5.0   5000.0  1143.0     5.0  11.0   110.0   8.0   0.0   5.0   \n",
       "\n",
       "             V189  ...   V242  V188  V239  V226   V185    V187    V231  V196  \\\n",
       "ref                ...                                                         \n",
       "201390679  9999.0  ...   15.0   8.0   0.0   3.0  113.0  9999.0   945.0   3.0   \n",
       "201390959  9999.0  ...   32.0   2.0  15.0   5.0    1.0  9999.0  1530.0   2.0   \n",
       "201397626  9999.0  ...   32.0   2.0  12.0   3.0  130.0  9999.0  1202.0   2.0   \n",
       "201397742  9999.0  ...   28.0   3.0  14.0   5.0   69.0  9999.0  1324.0   1.0   \n",
       "201401345     1.0  ...   18.0   4.0   0.0   3.0  181.0    28.0  1205.0   1.0   \n",
       "\n",
       "               V220  V202  \n",
       "ref                        \n",
       "201390679  102003.0  27.0  \n",
       "201390959   32005.0  47.0  \n",
       "201397626   92002.0  36.0  \n",
       "201397742   42002.0  25.0  \n",
       "201401345  112004.0  33.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_FI_up = X_up[col_FI_up]\n",
    "df_FI_up.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables cuya importancia sea > 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_FI_dwn = []\n",
    "count2 = 0\n",
    "for i in indices2:\n",
    "    if importances2[indices2[i]] > 0.01:\n",
    "        col_FI_dwn.append(col_X[i])\n",
    "        count2 += importances2[indices2[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74480149516753991"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['V240',\n",
       " 'V182',\n",
       " 'V189',\n",
       " 'V212',\n",
       " 'V180',\n",
       " 'V242',\n",
       " 'V244',\n",
       " 'V188',\n",
       " 'V243',\n",
       " 'V167',\n",
       " 'V186',\n",
       " 'V203',\n",
       " 'V191',\n",
       " 'V245',\n",
       " 'V196',\n",
       " 'V239',\n",
       " 'V185',\n",
       " 'V202',\n",
       " 'V187']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_FI_dwn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['V203',\n",
       " 'V191',\n",
       " 'V212',\n",
       " 'V202',\n",
       " 'V187',\n",
       " 'V185',\n",
       " 'V186',\n",
       " 'V180',\n",
       " 'V242',\n",
       " 'V167',\n",
       " 'V189',\n",
       " 'V188',\n",
       " 'V243',\n",
       " 'V196',\n",
       " 'V182',\n",
       " 'V245',\n",
       " 'V244',\n",
       " 'V239',\n",
       " 'V240',\n",
       " 'V241',\n",
       " 'V169',\n",
       " 'V226',\n",
       " 'V220',\n",
       " 'V231',\n",
       " 'V222',\n",
       " 'V172',\n",
       " 'V224',\n",
       " 'V216',\n",
       " 'V219',\n",
       " 'V221',\n",
       " 'V227',\n",
       " 'V214',\n",
       " 'V233',\n",
       " 'V246',\n",
       " 'V232',\n",
       " 'V197',\n",
       " 'V181',\n",
       " 'V178',\n",
       " 'V228',\n",
       " 'V229',\n",
       " 'V201',\n",
       " 'V211',\n",
       " 'V192',\n",
       " 'V168',\n",
       " 'V184',\n",
       " 'V171',\n",
       " 'V225',\n",
       " 'V200',\n",
       " 'X14',\n",
       " 'X13',\n",
       " 'X16',\n",
       " 'X9',\n",
       " 'X8',\n",
       " 'X11',\n",
       " 'X1',\n",
       " 'X3',\n",
       " 'X2',\n",
       " 'X17',\n",
       " 'X21',\n",
       " 'X18',\n",
       " 'X19',\n",
       " 'X20',\n",
       " 'V209_encoded',\n",
       " 'V183_encoded',\n",
       " 'V210_encoded',\n",
       " 'V175_encoded',\n",
       " 'V176_encoded',\n",
       " 'V198_encoded',\n",
       " 'V190_encoded',\n",
       " 'V193_encoded',\n",
       " 'V204_encoded',\n",
       " 'V218_encoded',\n",
       " 'V230_encoded',\n",
       " 'V217_encoded',\n",
       " 'V223_encoded',\n",
       " 'V215_encoded',\n",
       " 'V170_encoded',\n",
       " 'V177_encoded',\n",
       " 'V163_encoded',\n",
       " 'V164_encoded',\n",
       " 'V165_encoded',\n",
       " 'V166_encoded',\n",
       " 'X12_encoded',\n",
       " 'X7_encoded',\n",
       " 'X4_encoded',\n",
       " 'V213',\n",
       " 'V208',\n",
       " 'V205',\n",
       " 'V206',\n",
       " 'V179',\n",
       " 'V199',\n",
       " 'V195',\n",
       " 'V146',\n",
       " 'V147',\n",
       " 'V148',\n",
       " 'V150',\n",
       " 'V151',\n",
       " 'V152',\n",
       " 'V235',\n",
       " 'V236',\n",
       " 'V237',\n",
       " 'V155',\n",
       " 'V156',\n",
       " 'V157',\n",
       " 'V158',\n",
       " 'V159',\n",
       " 'V160',\n",
       " 'V153',\n",
       " 'V149',\n",
       " 'V238',\n",
       " 'V154',\n",
       " 'V161',\n",
       " 'V234',\n",
       " 'V194',\n",
       " 'V207',\n",
       " 'V173',\n",
       " 'V174']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_X\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe - Feature importances - Downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V240</th>\n",
       "      <th>V182</th>\n",
       "      <th>V189</th>\n",
       "      <th>V212</th>\n",
       "      <th>V180</th>\n",
       "      <th>V242</th>\n",
       "      <th>V244</th>\n",
       "      <th>V188</th>\n",
       "      <th>V243</th>\n",
       "      <th>V167</th>\n",
       "      <th>V186</th>\n",
       "      <th>V203</th>\n",
       "      <th>V191</th>\n",
       "      <th>V245</th>\n",
       "      <th>V196</th>\n",
       "      <th>V239</th>\n",
       "      <th>V185</th>\n",
       "      <th>V202</th>\n",
       "      <th>V187</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ref</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>220901784</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1135.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234159801</th>\n",
       "      <td>36.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1137.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>513.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215190020</th>\n",
       "      <td>9999.0</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>9999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212357512</th>\n",
       "      <td>9999.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232902445</th>\n",
       "      <td>6.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1136.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             V240     V182    V189    V212    V180  V242  V244  V188  V243  \\\n",
       "ref                                                                          \n",
       "220901784     1.0   9000.0     3.0  1135.0    30.0  20.0  10.0   4.0   5.0   \n",
       "234159801    36.0   3000.0     1.0  1137.0    18.0  28.0  21.0   3.0   3.0   \n",
       "215190020  9999.0  11000.0  9999.0  1125.0  9999.0  14.0  18.0   2.0   2.0   \n",
       "212357512  9999.0   9000.0  9999.0   198.0  9999.0  15.0  14.0   8.0  10.0   \n",
       "232902445     6.0   9000.0     2.0  1136.0    18.0  27.0   0.0   4.0   5.0   \n",
       "\n",
       "           V167    V186  V203  V191  V245  V196  V239   V185  V202    V187  \n",
       "ref                                                                         \n",
       "220901784   3.0   168.0   0.0  28.0   0.0   1.0  10.0  309.0  43.0    44.0  \n",
       "234159801   3.0    67.0   0.0  33.0   5.0   1.0  16.0  513.0  60.0    24.0  \n",
       "215190020   6.0  9999.0  99.0  28.0  16.0   5.0   2.0  327.0  45.0  9999.0  \n",
       "212357512   7.0  9999.0   0.0  43.0   0.0   2.0  14.0   36.0  30.0  9999.0  \n",
       "232902445   2.0   154.0   0.0   8.0   0.0   2.0   0.0   83.0  25.0    31.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_FI_dwn = X_dwn[col_FI_dwn]\n",
    "df_FI_dwn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODELOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ASAP: As Simple As Possible**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UPSAMPLED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=7, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_up = linear_model.LogisticRegression(random_state = seed)\n",
    "model_up.fit(df_FI_up,y_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "predictions_up = model_up.predict(df_FI_up)\n",
    "print(predictions_up[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ref\n",
       "201390679    0\n",
       "201390959    0\n",
       "201397626    0\n",
       "201397742    0\n",
       "201401345    0\n",
       "201402181    0\n",
       "201403985    0\n",
       "201404213    0\n",
       "201405542    0\n",
       "201405827    0\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_up[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93568347565309684"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_up.score(df_FI_up,y_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.20\n",
    "\n",
    "X_train_up, X_test_up, Y_train_up, Y_test_up = model_selection.train_test_split(df_FI_up, y_up, test_size=test_size, random_state=seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.935950 (0.001500)\n"
     ]
    }
   ],
   "source": [
    "name='Logistic Regression'\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "cv_results = model_selection.cross_val_score(model_up, X_train_up, Y_train_up, cv=kfold, scoring='accuracy')\n",
    "msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "print(msg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_up1 = model_up.predict(X_test_up)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.935468951583\n"
     ]
    }
   ],
   "source": [
    "print(model_up.score(X_train_up, Y_train_up))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.936541551044\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test_up, predictions_up1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19082  1445]\n",
      " [ 1162 19393]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test_up, predictions_up1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas_ml import ConfusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predicted      0      1  __all__\n",
       "Actual                          \n",
       "0          19082   1445    20527\n",
       "1           1162  19393    20555\n",
       "__all__    20244  20838    41082"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConfusionMatrix(Y_test_up.tolist(), predictions_up1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.93      0.94     20527\n",
      "          1       0.93      0.94      0.94     20555\n",
      "\n",
      "avg / total       0.94      0.94      0.94     41082\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test_up, predictions_up1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DOWNSAMPLED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=7, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dwn = linear_model.LogisticRegression(random_state = seed)\n",
    "model_dwn.fit(df_FI_dwn,y_dwn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "predictions_dwn = model_dwn.predict(df_FI_dwn)\n",
    "print(predictions_dwn[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ref\n",
       "220901784    0\n",
       "234159801    0\n",
       "215190020    0\n",
       "212357512    0\n",
       "232902445    0\n",
       "236278777    0\n",
       "204326101    0\n",
       "224675612    0\n",
       "204066333    0\n",
       "218689326    0\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dwn[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91618497109826591"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dwn.score(df_FI_dwn,y_dwn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_size = 0.20\n",
    "\n",
    "X_train_dwn, X_test_dwn, Y_train_dwn, Y_test_dwn = model_selection.train_test_split(df_FI_dwn, y_dwn, test_size=test_size, random_state=seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.914305 (0.020923)\n"
     ]
    }
   ],
   "source": [
    "name='Logistic Regression'\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "cv_results_dwn = model_selection.cross_val_score(model_dwn, X_train_dwn, Y_train_dwn, cv=kfold, scoring='accuracy')\n",
    "msg_dwn = \"%s: %f (%f)\" % (name, cv_results_dwn.mean(), cv_results_dwn.std())\n",
    "print(msg_dwn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_dwn1 = model_dwn.predict(X_test_dwn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.917398038203\n"
     ]
    }
   ],
   "source": [
    "print(model_dwn.score(X_train_dwn, Y_train_dwn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.911340206186\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test_dwn, predictions_dwn1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[211  26]\n",
      " [ 17 231]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test_dwn, predictions_dwn1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predicted    0    1  __all__\n",
       "Actual                      \n",
       "0          211   26      237\n",
       "1           17  231      248\n",
       "__all__    228  257      485"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConfusionMatrix(Y_test_dwn.tolist(), predictions_dwn1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.89      0.91       237\n",
      "          1       0.90      0.93      0.91       248\n",
      "\n",
      "avg / total       0.91      0.91      0.91       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test_dwn, predictions_dwn1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MEJOR MODELO POSIBLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UPSAMPLED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_up = svm.SVC(kernel='linear', random_state = seed) # We set a SVM classifier, the default SVM Classifier (Kernel = Radial Basis Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_up.fit(X_train_up, Y_train_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.926066794869\n"
     ]
    }
   ],
   "source": [
    "svm_pred_up = classifier_up.predict(X_test_up)\n",
    "print(classifier_up.score(X_train_up, Y_train_up))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.927291757948\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test_up, svm_pred_up))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18536  1991]\n",
      " [  996 19559]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test_up, svm_pred_up))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predicted      0      1  __all__\n",
       "Actual                          \n",
       "0          18536   1991    20527\n",
       "1            996  19559    20555\n",
       "__all__    19532  21550    41082"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas_ml import ConfusionMatrix\n",
    "ConfusionMatrix(Y_test_up.tolist(), svm_pred_up)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.90      0.93     20527\n",
      "          1       0.91      0.95      0.93     20555\n",
      "\n",
      "avg / total       0.93      0.93      0.93     41082\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test_up, svm_pred_up))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM Downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train_dwn, Y_train_dwn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_pred_dwn = classifier.predict(X_test_dwn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.912751677852\n"
     ]
    }
   ],
   "source": [
    "print(classifier.score(X_train_dwn, Y_train_dwn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.898969072165\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test_dwn, svm_pred_dwn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[208  29]\n",
      " [ 20 228]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test_dwn, svm_pred_dwn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predicted    0    1  __all__\n",
       "Actual                      \n",
       "0          208   29      237\n",
       "1           20  228      248\n",
       "__all__    228  257      485"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConfusionMatrix(Y_test_dwn.tolist(), svm_pred_dwn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM optimizar parámetros. Rejilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "  {'C': [1, 10], 'kernel': ['linear']},\n",
    "  {'C': [1, 10], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "svm = svm.SVC(random_state=1988)\n",
    "\n",
    "# crear grid search\n",
    "gs = GridSearchCV(estimator=svm, param_grid=param_grid, scoring='accuracy',\n",
    "                  cv=5,n_jobs=-1)\n",
    "\n",
    "# comenzar el ajuste\n",
    "gs_up = gs.fit(X_train_up, Y_train_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imprimir resultados\n",
    "print(gs_up.best_score_)\n",
    "print(gs_up.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utilizando el mejor modelo\n",
    "mejor_modelo_up = gs_up.best_estimator_\n",
    "mejor_modelo_up.fit(x_train_up, Y_train_up)\n",
    "print('Precisión: {0:.3f}'.format(mejor_modelo_up.score(X_test_up, Y_test_up)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM DOWNSAMPLED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_dwn = gs.fit(x_train_dwn, Y_train_dwn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imprimir resultados\n",
    "print(gs_dwn.best_score_)\n",
    "print(gs_dwn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utilizando el mejor modelo\n",
    "mejor_modelo_dwn = gs_dwn.best_estimator_\n",
    "mejor_modelo_dwn.fit(x_train_dwn, Y_train_dwn)\n",
    "print('Precisión: {0:.3f}'.format(mejor_modelo_dwn.score(X_test_dwn, Y_test_dwn)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RANDOM FOREST UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_up = RandomForestClassifier(n_estimators=200, random_state = seed)\n",
    "rf_up.fit(X_train_up, Y_train_up)\n",
    "\n",
    "rf_pred_up = rf_up.predict(X_test_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(rf_up.score(X_train_up, Y_train_up))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.999415802541\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test_up, rf_pred_up))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20503    24]\n",
      " [    0 20555]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test_up, rf_pred_up))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predicted      0      1  __all__\n",
       "Actual                          \n",
       "0          20503     24    20527\n",
       "1              0  20555    20555\n",
       "__all__    20503  20579    41082"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConfusionMatrix(Y_test_up.tolist(), rf_pred_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RANDOM FOREST DOWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_dwn = RandomForestClassifier(n_estimators=200, random_state = seed)\n",
    "rf_dwn.fit(X_train_dwn, Y_train_dwn)\n",
    "rf_pred_dwn = rf_dwn.predict(X_test_dwn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(rf_dwn.score(X_train_dwn, Y_train_dwn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.960824742268\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test_dwn, rf_pred_dwn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[228   9]\n",
      " [ 10 238]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test_dwn, rf_pred_dwn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predicted    0    1  __all__\n",
       "Actual                      \n",
       "0          228    9      237\n",
       "1           10  238      248\n",
       "__all__    238  247      485"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConfusionMatrix(Y_test_dwn.tolist(), rf_pred_dwn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Random Forest optimizar parámetros. Rejilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_up = RandomForestClassifier(random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'n_estimators': [200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isaac\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Isaac\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "CV_rfc_up = GridSearchCV(estimator=rfc_up, param_grid=param_grid, cv= 5)\n",
    "CV_rfc_up.fit(X_train_up, Y_train_up)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
